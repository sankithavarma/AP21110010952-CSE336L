{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZoUJvR2aqu4",
        "outputId": "e8487a96-b100-469c-c51f-23f8afac2172"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[0 1]\n",
            " [0 2]]\n",
            "\n",
            "Accuracy: 0.6666666666666666\n",
            "Precision: 0.6666666666666666\n",
            "Recall: 1.0\n",
            "F1 Score: 0.8\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the dataset\n",
        "data = {\n",
        "    'Outlook': ['Sunny', 'Sunny', 'Overcast', 'Rain', 'Rain', 'Rain', 'Overcast', 'Sunny', 'Sunny', 'Rain', 'Sunny', 'Overcast', 'Overcast', 'Rain'],\n",
        "    'Temp': ['Hot', 'Hot', 'Hot', 'Mild', 'Cool', 'Cool', 'Cool', 'Mild', 'Cool', 'Mild', 'Mild', 'Mild', 'Hot', 'Mild'],\n",
        "    'Humidity': ['High', 'High', 'High', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'Normal', 'Normal', 'High', 'Normal', 'High'],\n",
        "    'Wind': ['Weak', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Weak', 'Weak', 'Strong', 'Strong', 'Weak', 'Strong'],\n",
        "    'Decision': ['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes', 'Yes', 'Yes', 'Yes', 'No']\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Splitting the data into features and target variable\n",
        "X = df.drop('Decision', axis=1)\n",
        "y = df['Decision']\n",
        "\n",
        "# Convert categorical variables into dummy/indicator variables\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Implementing Naive Bayes Classifier\n",
        "class NaiveBayesClassifier:\n",
        "    def __init__(self):\n",
        "        self.priors = {}\n",
        "        self.posteriors = {}\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.classes = y.unique()\n",
        "        for cls in self.classes:\n",
        "            X_cls = X[y == cls]\n",
        "            self.priors[cls] = len(X_cls) / len(X)\n",
        "            self.posteriors[cls] = {}\n",
        "            for feature in X.columns:\n",
        "                self.posteriors[cls][feature] = {}\n",
        "                for value in X[feature].unique():\n",
        "                    self.posteriors[cls][feature][value] = (X_cls[feature] == value).sum() / len(X_cls)\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for _, instance in X.iterrows():\n",
        "            probs = {cls: self.priors[cls] for cls in self.classes}\n",
        "            for cls in self.classes:\n",
        "                for feature, value in instance.items():\n",
        "                    probs[cls] *= self.posteriors[cls][feature].get(value, 0)\n",
        "            predictions.append(max(probs, key=probs.get))\n",
        "        return predictions\n",
        "\n",
        "# Train the Naive Bayes classifier\n",
        "nb_classifier = NaiveBayesClassifier()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='binary', pos_label='Yes')\n",
        "recall = recall_score(y_test, y_pred, average='binary', pos_label='Yes')\n",
        "f1 = f1_score(y_test, y_pred, average='binary', pos_label='Yes')\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "y = pd.Series(iris.target)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Na√Øve Bayes classifier\n",
        "nb_classifier = GaussianNB()\n",
        "nb_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = nb_classifier.predict(X_test)\n",
        "\n",
        "# Evaluate the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred, average='weighted')\n",
        "recall = recall_score(y_test, y_pred, average='weighted')\n",
        "f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "print(\"\\nAccuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTDMJivacVd8",
        "outputId": "5d058a58-c618-434d-e8ed-c2c71dba1d1f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix:\n",
            "[[10  0  0]\n",
            " [ 0  9  0]\n",
            " [ 0  0 11]]\n",
            "\n",
            "Accuracy: 1.0\n",
            "Precision: 1.0\n",
            "Recall: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zyXqRW2ooCcL"
      }
    }
  ]
}